{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Image Classification Labs\n",
    "\n",
    "## Lab 3-2 Training ResNet with CIFAR 10 dataset using TensorFlow (Single Node)\n",
    "\n",
    "This lab is to train ResNet neural network with CIFAR-10 training data to classify an images into 10 known categories. The code is written in TensorFlow. \n",
    "\n",
    "Unlike Apache MXNet, TensorFlow does not yet support Amazon S3 storage. However, one issue in tensorflow git has been created with S3 file system support code. (https://github.com/tensorflow/tensorflow/issues/10616)\n",
    "\n",
    "\n",
    "\n",
    "### Where to execute trainig and evaluation ?\n",
    "\n",
    "You need to execute this in a ternimal not in jupyter notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Steps of  Lab 3-2\n",
    "\n",
    "Here I assume you cloned CodeCommit repository, and all necessary files are in lab3/tensorflow_resnet_cifar10 directory.\n",
    "\n",
    "##### Step 1. Create an Amazon S3 bucket for storing checkpoint (You may use the same bucket used in Lab 3-1)\n",
    "\n",
    "##### Step 2. Build resnet_main using bazel tool\n",
    "\n",
    "```\n",
    "$ cd lab3\n",
    "\n",
    "$ bazel build -c opt tensorflow_resnet_cifar10/...\n",
    "```\n",
    "\n",
    "> **Bazel** is Google's own build tool, now publicly available in Beta. Bazel has built-in support for building both client and server software, including client applications for both Android and iOS platforms. It also provides an extensible framework that you can use to develop your own build rules. \n",
    "\n",
    "##### Step 3. Run training using the below command\n",
    "\n",
    "```\n",
    "$ bazel-bin/tensorflow_resnet_cifar10/resnet_main \\\n",
    " --train_data_path=./tensorflow_resnet_cifar10/dataset/cifar-10-batches-bin/data_batch* \\\n",
    " --log_root=./tensorflow_resnet_cifar10/resnet_model \\\n",
    " --train_dir=./tensorflow_resnet_cifar10/resnet_model/train \\\n",
    " --log_root=./tensorflow_resnet_cifar10/resnet_model/ckpt \\\n",
    " --dataset='cifar10'\n",
    "```\n",
    "\n",
    "##### Step 4. Stop the training after 3-4 epoch\n",
    "\n",
    "##### Step 5. Run evaluation using the below command\n",
    "\n",
    "```\n",
    "$ bazel-bin/tensorflow_resnet_cifar10/resnet_main \\\n",
    "  --eval_data_path=./tensorflow_resnet_cifar10/dataset/cifar-10-batches-bin/test_batch.bin \\\n",
    "  --log_root=./tensorflow_resnet_cifar10/resnet_model/ckpt \\\n",
    "  --eval_dir=./tensorflow_resnet_cifar10/resnet_model/test \\\n",
    "  --mode=eval \\\n",
    "  --dataset='cifar10' \\\n",
    "  --num_gpus=0\n",
    "```\n",
    "\n",
    "#### Step 6. Upload checkpoint files to S3 bucket\n",
    "\n",
    "```\n",
    "$ cd ./tensorflow_resnet_cifar10/resnet_model/ckpt\n",
    "$ aws s3 sync . s3://<bucket_name>/deeplearning/tf-resnet-model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output from training\n",
    "\n",
    "This training program saves checkpoints every 500 steps (or epoch) into the directory specified by *log-root* parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checkpoint Files\n",
    "\n",
    "* model.ckpt-000.meta : Network design or graph structure\n",
    "* model.ckpt-000.data-00000-of-00001 : the values of each variable in the graph\n",
    "* model.ckpt-000.index : identifies the checkpiont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Analysis Report : Neural network architecture and the number of parameters\n",
    "```\n",
    "==================Model Analysis Report======================\n",
    "_TFProfRoot (--/464.15k params)\n",
    "  init/init_conv/DW (3x3x3x16, 432/432 params)\n",
    "  logit/DW (64x10, 640/640 params)\n",
    "  logit/biases (10, 10/10 params)\n",
    "  unit_1_0/shared_activation/init_bn/beta (16, 16/16 params)\n",
    "  unit_1_0/shared_activation/init_bn/gamma (16, 16/16 params)\n",
    "  unit_1_0/sub1/conv1/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_0/sub2/bn2/beta (16, 16/16 params)\n",
    "  unit_1_0/sub2/bn2/gamma (16, 16/16 params)\n",
    "  unit_1_0/sub2/conv2/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_1/residual_only_activation/init_bn/beta (16, 16/16 params)\n",
    "  unit_1_1/residual_only_activation/init_bn/gamma (16, 16/16 params)\n",
    "  unit_1_1/sub1/conv1/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_1/sub2/bn2/beta (16, 16/16 params)\n",
    "  unit_1_1/sub2/bn2/gamma (16, 16/16 params)\n",
    "  unit_1_1/sub2/conv2/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_2/residual_only_activation/init_bn/beta (16, 16/16 params)\n",
    "  unit_1_2/residual_only_activation/init_bn/gamma (16, 16/16 params)\n",
    "  unit_1_2/sub1/conv1/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_2/sub2/bn2/beta (16, 16/16 params)\n",
    "  unit_1_2/sub2/bn2/gamma (16, 16/16 params)\n",
    "  unit_1_2/sub2/conv2/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_3/residual_only_activation/init_bn/beta (16, 16/16 params)\n",
    "  unit_1_3/residual_only_activation/init_bn/gamma (16, 16/16 params)\n",
    "  unit_1_3/sub1/conv1/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_3/sub2/bn2/beta (16, 16/16 params)\n",
    "  unit_1_3/sub2/bn2/gamma (16, 16/16 params)\n",
    "  unit_1_3/sub2/conv2/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_4/residual_only_activation/init_bn/beta (16, 16/16 params)\n",
    "  unit_1_4/residual_only_activation/init_bn/gamma (16, 16/16 params)\n",
    "  unit_1_4/sub1/conv1/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  unit_1_4/sub2/bn2/beta (16, 16/16 params)\n",
    "  unit_1_4/sub2/bn2/gamma (16, 16/16 params)\n",
    "  unit_1_4/sub2/conv2/DW (3x3x16x16, 2.30k/2.30k params)\n",
    "  .... snipped ....\n",
    "  unit_3_4/residual_only_activation/init_bn/beta (64, 64/64 params)\n",
    "  unit_3_4/residual_only_activation/init_bn/gamma (64, 64/64 params)\n",
    "  unit_3_4/sub1/conv1/DW (3x3x64x64, 36.86k/36.86k params)\n",
    "  unit_3_4/sub2/bn2/beta (64, 64/64 params)\n",
    "  unit_3_4/sub2/bn2/gamma (64, 64/64 params)\n",
    "  unit_3_4/sub2/conv2/DW (3x3x64x64, 36.86k/36.86k params)\n",
    "  unit_last/final_bn/beta (64, 64/64 params)\n",
    "  unit_last/final_bn/gamma (64, 64/64 params)\n",
    "\n",
    "======================End of Report==========================\n",
    "total_params: 464154\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Output from evaluation\n",
    "\n",
    "Running this program in evaluation mode, it read the evaluation dataset and get predicted category to compare the real label. \n",
    "\n",
    "```\n",
    "INFO:tensorflow:Loading checkpoint ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:Restoring parameters from ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:loss: 1.231, precision: 0.694, best precision: 0.694\n",
    "INFO:tensorflow:Loading checkpoint ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:Restoring parameters from ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:loss: 1.082, precision: 0.692, best precision: 0.694\n",
    "INFO:tensorflow:Loading checkpoint ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:Restoring parameters from ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:loss: 1.231, precision: 0.694, best precision: 0.694\n",
    "INFO:tensorflow:Loading checkpoint ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:Restoring parameters from ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:loss: 1.082, precision: 0.692, best precision: 0.694\n",
    "INFO:tensorflow:Loading checkpoint ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:Restoring parameters from ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:loss: 1.231, precision: 0.694, best precision: 0.694\n",
    "INFO:tensorflow:Loading checkpoint ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "INFO:tensorflow:Restoring parameters from ./tensorflow_resnet_cifar10/resnet_model/ckpt/model.ckpt-1053\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing modules and define arguments with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import six\n",
    "import sys\n",
    "\n",
    "import cifar_input\n",
    "import numpy as np\n",
    "import resnet_model\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('dataset', 'cifar10', 'cifar10 or cifar100.')\n",
    "tf.app.flags.DEFINE_string('mode', 'train', 'train or eval.')\n",
    "tf.app.flags.DEFINE_string('train_data_path', './dataset/cifar-10-batches-bin/data_batch*',\n",
    "                           'Filepattern for training data.')\n",
    "tf.app.flags.DEFINE_string('eval_data_path', '',\n",
    "                           'Filepattern for eval data')\n",
    "tf.app.flags.DEFINE_integer('image_size', 32, 'Image side length.')\n",
    "tf.app.flags.DEFINE_string('train_dir', './resnet_model/train',\n",
    "                           'Directory to keep training outputs.')\n",
    "tf.app.flags.DEFINE_string('eval_dir', '',\n",
    "                           'Directory to keep eval outputs.')\n",
    "tf.app.flags.DEFINE_integer('eval_batch_count', 50,\n",
    "                            'Number of batches to eval.')\n",
    "tf.app.flags.DEFINE_bool('eval_once', False,\n",
    "                         'Whether evaluate the model only once.')\n",
    "tf.app.flags.DEFINE_string('log_root', './resnet_model/ckpt',\n",
    "                           'Directory to keep the checkpoints. Should be a '\n",
    "                           'parent directory of FLAGS.train_dir/eval_dir.')\n",
    "tf.app.flags.DEFINE_integer('num_gpus', 0,\n",
    "                            'Number of gpus used for training. (0 or 1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementing training\n",
    "\n",
    "In this code, tf.summary is used to save training summary data which later can be visualized by TensorBoard.\n",
    "\n",
    "> **TensorBoard for MXNet**\n",
    ">\n",
    "> TensorBoard is built together with TensorFlow. There is a git project to make a stand-alone version for general visualization purpose, and it is avaiable at https://github.com/dmlc/tensorboard\n",
    ">\n",
    "> Also, read [Bring TensorBoard to MXNet](http://dmlc.ml/2017/01/07/bring-TensorBoard-to-MXNet.html) for detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(hps):\n",
    "  \"\"\"Training loop.\"\"\"\n",
    "  images, labels = cifar_input.build_input(\n",
    "      FLAGS.dataset, FLAGS.train_data_path, hps.batch_size, FLAGS.mode)\n",
    "  model = resnet_model.ResNet(hps, images, labels, FLAGS.mode)\n",
    "  model.build_graph()\n",
    "\n",
    "  param_stats = tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
    "      tf.get_default_graph(),\n",
    "      tfprof_options=tf.contrib.tfprof.model_analyzer.\n",
    "          TRAINABLE_VARS_PARAMS_STAT_OPTIONS)\n",
    "  sys.stdout.write('total_params: %d\\n' % param_stats.total_parameters)\n",
    "\n",
    "  tf.contrib.tfprof.model_analyzer.print_model_analysis(\n",
    "      tf.get_default_graph(),\n",
    "      tfprof_options=tf.contrib.tfprof.model_analyzer.FLOAT_OPS_OPTIONS)\n",
    "\n",
    "  truth = tf.argmax(model.labels, axis=1)\n",
    "  predictions = tf.argmax(model.predictions, axis=1)\n",
    "  precision = tf.reduce_mean(tf.to_float(tf.equal(predictions, truth)))\n",
    "\n",
    "  summary_hook = tf.train.SummarySaverHook(\n",
    "      save_steps=100,\n",
    "      output_dir=FLAGS.train_dir,\n",
    "      summary_op=tf.summary.merge([model.summaries,\n",
    "                                   tf.summary.scalar('Precision', precision)]))\n",
    "\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors={'step': model.global_step,\n",
    "               'loss': model.cost,\n",
    "               'precision': precision},\n",
    "      every_n_iter=100)\n",
    "\n",
    "  class _LearningRateSetterHook(tf.train.SessionRunHook):\n",
    "    \"\"\"Sets learning_rate based on global step.\"\"\"\n",
    "\n",
    "    def begin(self):\n",
    "      self._lrn_rate = 0.1\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "      return tf.train.SessionRunArgs(\n",
    "          model.global_step,  # Asks for global step value.\n",
    "          feed_dict={model.lrn_rate: self._lrn_rate})  # Sets learning rate\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "      train_step = run_values.results\n",
    "      if train_step < 40000:\n",
    "        self._lrn_rate = 0.1\n",
    "      elif train_step < 60000:\n",
    "        self._lrn_rate = 0.01\n",
    "      elif train_step < 80000:\n",
    "        self._lrn_rate = 0.001\n",
    "      else:\n",
    "        self._lrn_rate = 0.0001\n",
    "\n",
    "  with tf.train.MonitoredTrainingSession(\n",
    "      checkpoint_dir=FLAGS.log_root,\n",
    "      hooks=[logging_hook, _LearningRateSetterHook()],\n",
    "      chief_only_hooks=[summary_hook],\n",
    "      # Since we provide a SummarySaverHook, we need to disable default\n",
    "      # SummarySaverHook. To do that we set save_summaries_steps to 0.\n",
    "      save_summaries_steps=0,\n",
    "      config=tf.ConfigProto(allow_soft_placement=True)) as mon_sess:\n",
    "    while not mon_sess.should_stop():\n",
    "      mon_sess.run(model.train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementing evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(hps):\n",
    "  \"\"\"Eval loop.\"\"\"\n",
    "  images, labels = cifar_input.build_input(\n",
    "      FLAGS.dataset, FLAGS.eval_data_path, hps.batch_size, FLAGS.mode)\n",
    "  model = resnet_model.ResNet(hps, images, labels, FLAGS.mode)\n",
    "  model.build_graph()\n",
    "  saver = tf.train.Saver()\n",
    "  summary_writer = tf.summary.FileWriter(FLAGS.eval_dir)\n",
    "\n",
    "  sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "  tf.train.start_queue_runners(sess)\n",
    "\n",
    "  best_precision = 0.0\n",
    "  while True:\n",
    "    try:\n",
    "      ckpt_state = tf.train.get_checkpoint_state(FLAGS.log_root)\n",
    "    except tf.errors.OutOfRangeError as e:\n",
    "      tf.logging.error('Cannot restore checkpoint: %s', e)\n",
    "      continue\n",
    "    if not (ckpt_state and ckpt_state.model_checkpoint_path):\n",
    "      tf.logging.info('No model to eval yet at %s', FLAGS.log_root)\n",
    "      continue\n",
    "    tf.logging.info('Loading checkpoint %s', ckpt_state.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt_state.model_checkpoint_path)\n",
    "\n",
    "    total_prediction, correct_prediction = 0, 0\n",
    "    for _ in six.moves.range(FLAGS.eval_batch_count):\n",
    "      (summaries, loss, predictions, truth, train_step) = sess.run(\n",
    "          [model.summaries, model.cost, model.predictions,\n",
    "           model.labels, model.global_step])\n",
    "\n",
    "      truth = np.argmax(truth, axis=1)\n",
    "      predictions = np.argmax(predictions, axis=1)\n",
    "      correct_prediction += np.sum(truth == predictions)\n",
    "      total_prediction += predictions.shape[0]\n",
    "\n",
    "    precision = 1.0 * correct_prediction / total_prediction\n",
    "    best_precision = max(precision, best_precision)\n",
    "\n",
    "    precision_summ = tf.Summary()\n",
    "    precision_summ.value.add(\n",
    "        tag='Precision', simple_value=precision)\n",
    "    summary_writer.add_summary(precision_summ, train_step)\n",
    "    best_precision_summ = tf.Summary()\n",
    "    best_precision_summ.value.add(\n",
    "        tag='Best Precision', simple_value=best_precision)\n",
    "    summary_writer.add_summary(best_precision_summ, train_step)\n",
    "    summary_writer.add_summary(summaries, train_step)\n",
    "    tf.logging.info('loss: %.3f, precision: %.3f, best precision: %.3f' %\n",
    "                    (loss, precision, best_precision))\n",
    "    summary_writer.flush()\n",
    "\n",
    "    if FLAGS.eval_once:\n",
    "      break\n",
    "\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implementing main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  if FLAGS.num_gpus == 0:\n",
    "    dev = '/cpu:0'\n",
    "  elif FLAGS.num_gpus == 1:\n",
    "    dev = '/gpu:0'\n",
    "  else:\n",
    "    raise ValueError('Only support 0 or 1 gpu.')\n",
    "\n",
    "  if FLAGS.mode == 'train':\n",
    "    batch_size = 128\n",
    "  elif FLAGS.mode == 'eval':\n",
    "    batch_size = 100\n",
    "\n",
    "  if FLAGS.dataset == 'cifar10':\n",
    "    num_classes = 10\n",
    "  elif FLAGS.dataset == 'cifar100':\n",
    "    num_classes = 100\n",
    "\n",
    "  hps = resnet_model.HParams(batch_size=batch_size,\n",
    "                             num_classes=num_classes,\n",
    "                             min_lrn_rate=0.0001,\n",
    "                             lrn_rate=0.1,\n",
    "                             num_residual_units=5,\n",
    "                             use_bottleneck=False,\n",
    "                             weight_decay_rate=0.0002,\n",
    "                             relu_leakiness=0.1,\n",
    "                             optimizer='mom')\n",
    "\n",
    "  with tf.device(dev):\n",
    "    if FLAGS.mode == 'train':\n",
    "      train(hps)\n",
    "    elif FLAGS.mode == 'eval':\n",
    "      evaluate(hps)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
